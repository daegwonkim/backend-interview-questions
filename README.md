<div align="center">
  <a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Black+Han+Sans&size=40&duration=3000&pause=1000&color=0EBB12&center=true&vCenter=true&width=450&lines=%EB%B0%B1%EC%97%94%EB%93%9C+%EA%B0%9C%EB%B0%9C%EC%9E%90+%EB%A9%B4%EC%A0%91+%EC%A7%88%EB%AC%B8+%EC%A0%95%EB%A6%AC" alt="Typing SVG" /></a>  
</div>

## 🎯 Introduction
백엔드 개발 면접을 준비하면서 정리한 질문과 답변 모음집입니다.  
CS, 프로그래밍 언어, 프레임워크, 데이터베이스, Web, 보안 관련 내용을 다룹니다.

## 📌 Index
- [CS](#-cs)
- [Programing Language](#-programing-language)
- [Framework](#-framework)
- [Database](#-database)
- [Web](#-web)
- [Security](#-security)

## 💡 Questions
### 🖥 CS
#### 운영체제
<details>
  <summary>프로세스와 스레드의 차이에 대해 설명해주세요.</summary><br>
  
  프로세스와 스레드는 운영체제에서 <b>실행의 단위</b>를 나타내는 개념입니다.<br>
  
  <b>프로세스</b>는 현재 실행 중인 프로그램을 의미하고, 각 프로세스는 독립적인 메모리 공간을 가지고 있으며, 다른 프로세스와 완전히 분리되어 있습니다.<br>
  
  <b>스레드</b>는 프로세스 내에서 실행되는 작업의 단위이며, 하나의 프로세스 안에 여러 개의 스레드가 있을 수 있습니다. 스레드들은 같은 프로세스의 메모리 공간(스택 영역 제외)을 공유합니다.<br>

  주요 차이점을 요약하면 다음과 같습니다.
  1. 프로세스는 독립적인 메모리 공간을 가지지만 스레드는 코드, 데이터, 힙 영역을 공유하고 스택 영역만 따로 갖습니다.<br>
  2. 프로세스 간에는 서로 통신을 통해서 자원을 공유하고 데이터를 주고받아야 하지만, 스레드는 공유 메모리를 통해서 쉽게 데이터를 공유할 수 있습니다.<br>
  3. 프로세스는 하나의 프로세스가 죽어도 다른 프로세스에 영향을 주지 않지만, 스레드는 하나에 문제가 생기면 해당 스레드를 포함하고 있는 전체 프로세스가 영향을 받을 수 있습니다.
</details>
<details>
  <summary>스레드를 사용하는 이유에 대해 설명해주세요.</summary><br>

  스레드를 사용하는 가장 큰 이유는 <b>동시성을 통한 성능 향상</b>입니다.<br>

  단일 스레드로는 하나의 작업이 끝날 때까지 다른 작업을 할 수 없지만, 멀티 스레드를 사용하면 여러 작업을 동시에 처리할 수 있어 전체적인 처리량이 증가합니다.<br>

  또 파일 읽기, 네트워크 통신, 데이터베이스 쿼리와 같은 I/O 작업은 시간이 오래 걸리는데, 이때 다른 스레드가 CPU를 사용해서 다른 작업을 처리할 수 있어서 <b>I/O 블로킹 문제</b>도 해결할 수 있습니다.
</details>
<details>
  <summary>스레드는 최대한 많이 생성해서 사용하면 좋을까요?</summary><br>

  Java에서 각 스레드는 기본적으로 1~2MB 정도의 스택 메모리를 할당받습니다. 이는 결코 적은 양이 아니기 때문에 스레드를 무작정 많이 생성하면 추후에 <b>메모리 부족 현상</b>이 발생할 수 있습니다.<br>

  또한 CPU 코어의 수는 한정적인데 스레드 수만 많아지면 OS가 계속해서 스레드를 교체하면서 실행해야 하므로, 이 과정에서 발생하는 <b>컨텍스트 스위칭 오버헤드</b>로 인해 성능이 나빠질 수 있습니다.<br>

  더불어 스레드를 만들고 없애는 작업 자체도 시스템 리소스를 많이 사용하기 때문에 <b>스레드 생성 및 소멸 비용</b>도 무시할 수 없습니다.<br>

  따라서 스레드를 사용할 때에는 <b>Thread Pool</b>을 사용해서 적절한 개수의 스레드를 미리 생성해두고 재사용하는 방식을 주로 사용합니다.<br>

  결국에는 적절한 수가 핵심이고, 모니터링을 통해 최적의 스레드 수를 찾아가는 것이 중요합니다.
</details>
<details>
  <summary>메모리 구조에 대해 설명해주세요.</summary><br>
  
  메모리 구조는 크게 코드 영역, 데이터 영역, 힙 영역, 스택 영역으로 구분됩니다.<br>
  
  <b>코드 영역</b>은 실행할 프로그램의 코드가 저장되는 영역으로, 컴파일된 기계어 명령어들이 저장됩니다.<br>
  사용자가 프로그램 실행 명령을 내리면 OS에서는 디스크에서 메모리의 코드 영역으로 실행 코드를 올리게 되고, CPU는 코드 영역에 저장된 명령어를 하나씩 실행하게 됩니다.<br>

  <b>데이터 영역</b>은 프로그램 실행에 필요한 전역 변수와 정적 변수가 저장되는 영역입니다.<br>
  
  <b>힙 영역</b>은 동적으로 할당되는 메모리 공간으로, `malloc()`이나 `new`와 같은 함수로 런타임에 메모리를 요청할 경우 사용됩니다.<br>
  
  <b>스택 영역</b>은 함수 호출과 관련된 데이터가 저장되는 공간으로, 매개 변수나 지역 변수와 같은 데이터가 스택 프레임의 형태로 저장됩니다.<br>
  함수가 호출되면 스택에 스택 프레임이 쌓이고, 함수가 종료되면 스택 프레임이 제거되는 방식으로 동작합니다.
</details>
<details>
  <summary>컨텍스트 스위칭에 대해 설명해주세요.</summary><br>

  컨텍스트 스위칭이란 <b>CPU가 현재 실행중인 프로세스나 스레드의 실행을 중단하고 다른 프로세스나 스레드로 전환하는 과정</b>을 말합니다.<br>

  현재 실행중인 프로세스의 상태를 <b>PCB(Process Control Block)</b>에 저장하고, 다음에 실행할 프로세스의 상태를 PCB에서 불러와서 CPU 레지스터에 복원하는 방식으로 동작합니다.<br>

  컨텍스트 스위칭이 발생하는 기준은 다음과 같습니다.
  1. 시분할 시스템에서 타임 슬라이스가 끝난 경우
  2. I/O 작업으로 프로세스가 대기 상태에 들어간 경우
  3. 우선순위가 높은 프로세스가 대기열에 들어선 경우
  4. 프로세스가 종료된 경우
</details>
<details>
  <summary>CPU 스케줄링 알고리즘에 대해 설명해주세요.</summary><br>

  CPU 스케줄링 알고리즘이란 <b>여러 프로세스가 CPU를 사용하려고 할 때 어떤 순서로 CPU를 할당할지 결정하는 방법</b>을 말합니다.<br>

  <b>FCFS(First Come First Served) 스케줄링 기법</b>은 먼저 도착한 프로세스부터 처리하는 가장 간단한 방식으로, 공정하지만 작업 시간이 긴 프로세스가 먼저 도착하면 뒤의 짧은 작업들이 오래 기다려야 하는 <b>콘보이 현상</b>이 발생할 수 있습니다.

  <b>SJF(Shortest Job First) 스케줄링 기법</b>은 실행 시간이 가장 짧은 프로세스부터 처리하는 방식으로, 평균 대기 시간을 최소화할 수 있지만, 프로세스의 실행 시간을 미리 알기가 어렵고 실행 시간이 긴 프로세스의 경우에는 계속 실행이 지연되어 <b>기아 현상</b>이 발생할 수 있습니다.<br>

  <b>Round Robin 스케줄링 기법</b>은 각 프로세스에게 동일한 시간 할당량(타임 슬라이스)을 주고 돌아가면서 실행시키는 방식으로, 응답시간이 좋고 공정하지만 타임 슬라이스가 너무 짧으면 <b>컨텍스트 스위칭 오버헤드</b>로 인해 성능에 문제가 생길 수 있습니다.<br>

  <b>우선순위 스케줄링 기법</b>은 각 프로세스에 우선순위를 부여해서 높은 우선순위의 프로세스부터 처리하는 방식으로, 중요한 작업을 먼저 처리할 수 있지만 낮은 우선순위 프로세스의 경우 계속 실행이 지연되어 <b>기아 현상</b>이 발생할 수 있습니다.<br>

  <b>다단계 피드백 큐 스케줄링 기법</b>은 여러 개의 큐를 두고 프로세스의 행동에 따라 우선순위를 동적으로 조정하는 방식으로, CPU 집약적인 프로세스는 낮은 우선순위로, I/O 집약적인 프로세스는 높은 우선순위로 관리하며 CPU 실행 효율성을 높이는 기법입니다.

  > <b>콘보이 현상</b><br>
  > 콘보이 현상이란 작업 시간이 긴 프로세스에 의해 다른 프로세스의 실행이 전부 늦춰지는 현상을 말합니다.<br>
  > FCFS 스케줄링은 <b>비선점형 스케줄링 방식</b>으로, I/O 작업으로 인해 프로세스가 대기 상태로 전환되거나 프로세스가 완전히 종료되기 전까지는 다른 프로세스를 실행할 수 없기 때문에 이러한 현상이 발생할 수 있습니다.

  > <b>기아 현상</b><br>
  > 기아 현상이란 특정 프로세스가 계속해서 자원을 할당받지 못해 무한정 기다리게 되는 상황을 말합니다.<br>
  > 즉, SJF나 우선순위 스케줄링 방식에서 우선순위가 높은 프로세스들이 계속 들어오면서 우선순위가 낮은 프로세스는 영원히 실행되지 못하는 것을 의미하며, 이에 대한 가장 일반적인 해결책은 프로세스가 오래 기다릴수록 우선순위를 점진적으로 높여주는 <b>에이징(aging) 기법</b>을 사용하는 것입니다.
</details>
<details>
  <summary>선점형 스케줄링과 비선점형 스케줄링의 차이에 대해 설명해주세요.</summary><br>

  선점형 스케줄링과 비선점형 스케줄링은 <b>현재 실행중인 프로세스로부터 CPU를 강제로 빼앗을 수 있는지에 대한 개념</b>을 말합니다.<br>

  <b>비선점형 스케줄링</b>에서는 한 번 CPU를 할당받은 프로세스는 작업이 완료되거나 자발적으로 CPU 반납하지 않는 이상 계속 실행됩니다.<br>
  즉, 운영체제가 강제로 CPU를 빼앗을 수 없으며, 대표적인 예로 FCFS, SJF 스케줄링이 있습니다.<br>
  비선점형 스케줄링은 구현이 간단하고 컨텍스트 스위칭 오버헤드가 적지만, 작업 시간이 긴 프로세스가 CPU를 독점할 경우 응답 시간이 나빠질 수 있습니다.<br>

  <b>선점형 스케줄링</b>에서는 운영체제가 필요에 따라 현재 실행중인 프로세스로부터 CPU를 강제로 빼앗을 수 있습니다.<br>
  타임 슬라이스가 끝나거나 더 높은 우선순위 프로세스가 나타나면 현재 프로세스를 중단시키고 다른 프로세스를 실행하는 방식으로, 대표적인 예로 Round Robin이나 우선순위 스케줄링이 있습니다.<br>
  선점형 스케줄링은 응답 시간이 좋고 공정하지만, 컨텍스트 스위칭 오버헤드가 커질 수 있습니다.
</details>
<details>
  <summary>동기와 비동기의 차이에 대해 설명해주세요.</summary><br>

  동기와 비동기는 <b>작업의 실행 방식과 결과를 기다리는 방법에 대한 개념</b>을 말합니다.<br>

  <b>동기(Synchronous)</b>란 작업을 순차적으로 실행하는 방식으로, 하나의 작업이 완전이 끝날 때까지 기다렸다가 다음 작업을 실행합니다.<br>
  동기 방식은 코드가 직관적이고 이해하기 쉽지만, 느린 작업이 포함되어 있으면 전체적인 성능에 악영향을 미칠 수 있다는 특징을 갖고 있습니다.<br>

  <b>비동기(Asynchronous)</b>란 작업을 시작한 후 해당 작업에 대한 완료를 기다리지 않고 또 다른 작업 요청을 받아서 처리하는 방식으로, 나중에 작업이 완료된 것이 감지되면 그때 결과를 처리합니다.<br>
  비동기 방식은 효율적이고 응답성이 좋지만, 코드가 복잡해지고 디버깅이 어려워질 수 있다는 특징을 갖고 있습니다.
</details>
<details>
  <summary>Blocking I/O와 Non-blocking I/O의 차이에 대해 설명해주세요.</summary><br>

  Blocking I/O와 Non-blocking I/O는 <b>입출력 작업을 처리하는 방식에 대한 개념</b>을 말합니다.<br>

  <b>Blocking I/O</b>는 I/O 작업을 요청한 후 그 작업이 완료될 때까지 스레드가 대기하는 방식으로, 예를 들어 파일을 읽는 함수를 호출하면 파일 읽기가 완전히 끝날 때까지 해당 스레드는 다른 작업을 수행할 수 없게 됩니다.<br>
  코드는 간단하지만 효율성이 떨어진다는 특징을 갖고 있습니다.<br>

  <b>Non-blocking I/O</b>는 I/O 작업을 요청한 후 스레드가 커널로부터 바로 제어권을 반환 받아서 다른 작업을 처리할 수 있는 방식으로, 이후 polling이나 커널의 system call을 통해 작업이 완료되었음을 확인합니다.<br>
  Blocking 방식에 비해 효율적이지만, polling 방식을 사용할 경우 CPU 사용량이 늘어날 수 있습니다.
</details>
<details>
  <summary>멀티 스레드 프로그래밍에 대해 설명해주세요.</summary><br>

  멀티 스레드 프로그래밍이란 <b>하나의 프로세스 내에서 여러 개의 스레드를 생성하여 작업을 병렬로 처리하는 프로그래밍 기법</b>입니다.<br>

  이때 각 스레드는 같은 프로세스의 메모리 공간(스택 영역 제외)을 공유하며, 독립적인 실행 흐름을 갖습니다.<br>

  멀티 스레드를 사용하면 CPU 코어를 효율적으로 활용할 수 있고, I/O 작업 중에도 다른 스레드가 작업을 계속할 수 있어서 전체적인 처리량이 늘어납니다.<br>

  다만, 여러 스레드가 공유 데이터에 동시에 접근하는 경우에는 예상치 못한 결과가 나오거나(Race Condition), 교착상태가 발생할 수도 있습니다.<br>

  따라서 멀티 스레드 환경에서는 뮤텍스, 세마포어 같은 동기화 도구를 사용해서 임계 영역에는 한 번에 하나의 스레드만 접근할 수 있도록 동기화 처리를 하는 것이 중요합니다.
</details>
<details>
  <summary>멀티 스레드 환경에서의 동기화 기법에 대해 설명해주세요.</summary><br>

  멀티 스레드 환경에서 공유 자원에 대한 접근을 제어해서 데이터의 일관성을 보장하는 방법으로 사용되는 도구는 크게 3가지가 있습니다.<br>

  <b>뮤텍스(Mutex)</b>는 가장 기본적인 동기화 도구로, <b>한 번에 하나의 스레드</b>만 임계 영역에 접근할 수 있도록 합니다.<br>
  즉, 임계 영역에 진입할 수 있는 열쇠가 하나 뿐이며, 특정 스레드가 락을 획득하면 다른 스레드들은 락이 해제될 때까지 기다려야 합니다.<br>

  <b>세마포어는(Semaphore)</b>는 뮤텍스를 일반화한 개념으로, <b>동시에 접근할 수 있는 스레드의 개수를 제한</b>하는 방식입니다.<br>
  즉, 정해진 카운트에 따라 임계 영역에 동시에 접근할 수 있는 스레드의 개수가 정해지며, 뮤텍스와 마찬가지로 락을 획득하고 해제하는 작업을 통해 동기화가 이루어집니다.<br>

  <b>모니터(Monitor)</b>는 뮤텍스에 <b>조건 변수</b>를 추가한 동기화 도구로, 조건 변수란 특정 조건이 참이 될 때까지 스레드를 대기시키는 도구를 말합니다. (주로 생산자-소비자 문제에서 버퍼가 비어있을 때 소비자를 기다리게 하는 용도로 많이 사용됨)<br>
  따라서 모니터는 단순한 락 획득/해제 뿐만 아니라 조건 변수를 통한 조건 기반 대기와 통지 매커니즘을 제공하여 더 정교한 제어가 가능합니다.
</details>
<details>
  <summary>레이스 컨디션에 대해 설명해주세요.</summary><br>

  레이스 컨디션(Race Condition)이란 <b>둘 이상의 프로세스나 스레드가 공유 자원에 동시에 접근하여 변경하려고 할 때, 실행 순서에 따라 예상치 못한 결과가 나오는 현상</b>을 말합니다.<br>

  레이스 컨디션의 가장 큰 문제는 항상 발생하는 것이 아니라 타이밍에 따라 간헐적으로 발생한다는 점으로, 찾기도 어렵고 재현하기도 힘들어서 멀티 스레드 환경에서 가장 조심해야하는 부분입니다.
</details>
<details>
  <summary>교착상태에 대해 설명해주세요.</summary><br>

  교착상태(Deadlock)란 <b>두 개 이상의 프로세스나 스레드가 서로가 가진 자원을 기다리면서 무한정 대기하는 상태</b>를 말합니다.<br>

  교착 상태는 프로세스나 스레드가 서로 자원을 점유하려고 하는 과정에서 아래 네 가지 필요조건이 동시에 충족될 경우 발생합니다.
  - <b>상호배제</b>: 자원은 한 번에 하나의 프로세스만 사용할 수 있다.
  - <b>비선점</b>: 다른 프로세스의 자원을 강제로 빼앗을 수 없다.
  - <b>점유와 대기</b>: 자원을 할당받은 상태에서 또 다른 자원을 기다리는 상태
  - <b>순환 대기</b>: 프로세스들이 원형으로 서로의 자원을 기다리는 상태

  교착상태를 해결하기 위한 방법으로는 크게 3가지가 있습니다.
  - <b>교착상태 예방</b>: 교착상태가 발생하는 조건 중 하나라도 충족하지 않도록 설계하는 방법
  - <b>교착상태 회피</b>: 교착 상태가 발생할 가능성을 배제하지 않고 자원을 적당히 할당하다가 교착상태의 위험이 있을 때에는 자원을 할당하지 않는 방법. 즉, 안전한 상태에서만 자원을 할당하는 방법으로, 대표적으로는 <b>은행원 알고리즘(Banker's Algorithm)</b>이 있다.
  - <b>검출 후 회복</b>: 자원을 제약 없이 할당하다가 교착상태가 발생하면 해결하는 방법
</details>
<details>
  <summary>가상 메모리에 대해 설명해주세요.</summary><br>

  가상 메모리란 <b>실행하고자 하는 프로그램의 일부만 메모리에 적재하는 메모리 관리 기법</b>입니다.<br>

  이를 통해 실제 메모리 크기보다 큰 프로그램도 실행할 수 있고, 여러 프로세스가 메모리를 효율적으로 공유할 수 있습니다.<br>

  주로 프로세스의 논리 주소 공간과 메모리의 물리 주소 공간을 페이지와 프레임이라고 하는 일정한 단위로 나누어서 관리하는 <b>페이징 기법</b>을 사용하여 구현하며, 운영체제는 물리 메모리와 디스크 간에 페이지를 교체하면서 가상 메모리 시스템을 구현합니다.<br>

  이때 보편적으로 사용되는 페이지 교체 알고리즘은 <b>LRU(Least Recently Used)</b> 알고리즘으로, 이는 실제 메모리 상의 페이지들 중에서 가장 오랫동안 사용되지 않은 페이지를 교체하는 방식입니다.

  > <b>논리 주소와 물리 주소</b><br>
  > 논리 주소와 물리 주소는 메모리 관리 측면에서 사용되는 두 가지의 다른 주소 체계입니다.<br>
  > <b>논리 주소(가상 주소)</b>는 프로세스가 바라보는 논리적인 주소로, 프로세스 입장에서는 항상 0번지부터 시작하는 연속된 메모리 공간을 가진 것처럼 보입니다.<br>
  > <b>물리 주소</b>는 하드웨어가 실제로 접근하는 메모리의 물리적인 주소를 말합니다.<br>
  > CPU는 논리 주소로 메모리에 접근하며, 이 논리 주소는 <b>MMU(Memory Management Unit)</b>에 의해 물리 주소로 변환되어 실제 메모리 주소에 접근하게 됩니다.

  > <b>페이지 폴트(Page Fault)</b><br>
  > 페이지 폴트란 <b>프로세스가 접근하려는 페이지가 가상 메모리에는 존재하지만, 물리 메모리에는 존재하는 않을 때 발생하는 예외 상황</b>을 말합니다.<br>
  > 페이지 폴트가 발생하면 운영체제는 디스크에서 해당 페이지를 찾아서 메모리로 가져오는 과정을 거치게 되며, 이때 디스크 I/O가 발생하므로 페이지 폴트가 자주 발생하는 경우 시스템 성능이 크게 떨어질 수 있습니다.
</details>
<details>
  <summary>캐시에 대해 설명해주세요.</summary><br>

  캐시(Cache)란 <b>자주 사용되는 데이터를 가까운 저장소에 임시로 보관해서 시스템의 성능을 향상시키는 기법</b>입니다.<br>

  캐시 저장소는 CPU와 가깝기 때문에 메모리나 디스크에서 데이터를 읽는 것보다 훨씬 빨라, 자주 사용하는 데이터의 경우에는 캐시에 이를 저장하고 읽는 방식으로 성능을 높일 수 있습니다.<br>

  캐시에 저장될 데이터는 아래와 같은 기준에 따라 결정됩니다.
  - <b>시간 지역성</b>: 어떤 데이터가 최근에 사용되었다면, 가까운 미래에 다시 사용될 가능성이 높다는 원리
  - <b>공간 지역성</b>: 특정 데이터에 접근할 때, 그 데이터와 메모리상에서 인접한 다른 데이터도 함께 접근될 가능성이 높다는 원리
</details><br>

#### 네트워크
<details>
  <summary>OSI 7 계층에 대해 설명해주세요.</summary><br>

  OSI 7 계층은 네트워크 통신 과정을 7개의 단계로 나누어서 표준화한 네트워크 참조 모델입니다.<br>

  <b>1계층은 물리 계층(Physical Layer)</b>으로, 0과 1의 비트를 전기 신호로 변환하여 전송하는 계층입니다.<br>
  물리 계층에는 주소 개념이 없으며 송수신만 이루어질 뿐 전송되는 데이터에 대해 어떠한 조작이나 판단도 하지 않습니다.<br>
  케이블, 허브, 리피터 같은 물리적 장비들이 여기에 해당합니다.<br>

  <b>2계층은 데이터 링크 계층(Data Link Layer)</b>으로, 같은 네트워크(LAN) 내에 있는 호스트 간의 데이터 전송을 담당합니다.<br>
  데이터링크 계층에는 주소 개념이 있으며, MAC 주소를 사용해서 프레임 단위로 데이터를 전송합니다. 스위치, 브리지가 이 계층에서 동작합니다.<br>
  
  <b>3계층은 네트워크 계층(Network Layer)</b>으로, LAN을 넘어서 서로 다른 네트워크 간의 경로를 찾아 통신할 수 있도록 하는 계층입니다.<br>
  여기에서는 IP 주소를 사용해서 패킷을 목적지까지 라우팅하며, 라우터가 이 계층에서 작동하고, 대표적인 프로토콜로 IP 프로토콜, ARP 프로토콜이 있습니다.<br>
  
  <b>4계층은 전송 계층(Transport Layer)</b>으로, 애플리케이션 간 데이터 전송을 담당합니다.<br>
  포트 번호를 사용해서 네트워크 상의 애플리케이션을 식별하여 어디에 데이터를 전달할지 결정하며, TCP와 UDP가 이 계층의 대표적인 프로토콜입니다. <br>
  
  <b>5계층은 세션 계층(Session Layer)</b>으로, 애플리케이션 간의 통신에서 세션을 관리하는 계층이며, 연결 설정, 유지, 종료 및 동기화 기능을 제공합니다.<br>
  
  <b>6계층은 표현 계층(Presentation Layer)</b>으로, 애플리케이션 간의 통신에서 메시지 포맷을 관리하는 계층이며, 암호화, 압축, 인코딩 같은 작업을 수행합니다.
  
  <b>7계층은 응용 계층(Application Layer)</b>으로, 사용자와 직접 상호작용하는 계층이며, 애플리케이션 목적에 맞는 통신 방법을 제공합니다.<br>
  HTTP, FTP, SMTP, DNS 같은 프로토콜들이 이 계층에서 동작합니다.<br>
  
  이렇계 네트워크를 설계하면, 각 계층이 독립적으로 동작하여 하나의 계층에 문제가 생겨도 다른 계층에 영향을 주지 않고, 네트워크 문제가 발생했을 때 이를 체계적으로 분석할 수 있습니다.
</details>
<details>
  <summary>TCP와 UDP에 대해 설명해주세요.</summary><br>

  TCP와 UDP는 전송 계층에서 사용되는 두 가지 프로토콜로, <b>데이터 전송 방식</b>에서 차이가 있습니다.<br>

  <b>TCP(Transmission Control Protocol)</b>는 <b>연결 지향적 프로토콜</b>로, 데이터를 전송하기 전에 먼저 연결을 설정합니다.<br>
  TCP는 3-way handshake를 통해 연결을 맺고, 4-way handshake로 연결을 종료합니다.<br>
  TCP의 가장 큰 특징은 신뢰성으로, 데이터가 순차적으로 전달되는 것을 보장하고, 오류 제어 기능을 통해 패킷이 손실되면 재전송하여 모든 데이터가 정확하게 도작하도록 보장합니다. 또한 흐름 제어와 혼잡 제어 기능을 통해 네트워크 상황에 맞게 전송 속도를 조절할 수 있습니다.<br>

  <b>UDP(User Datagram Protocol)</b>는 <b>비연결 지향적 프로토콜</b>로, 연결 설정 과정 없이 바로 데이터를 전송합니다.<br>
  때문에 속도가 빠르고 오버헤드가 적지만, 신뢰성은 보장하지 않습니다. 즉, 패킷이 순서대로 도착하지 않을 수 있고, 손실될 수도 있습니다.<br>

  따라서 TCP는 이메일, 파일 전송처럼 데이터의 정확성이 중요한 곳에 주로 사용되고, UDP는 실시간 게임이나 동영상 스트리밍처럼 속도가 중요하고 약산의 손실은 허용할 수 있는 경우에 주로 사용됩니다.
</details>
<details>
  <summary>TCP의 3-way handshake, 4-way handshake에 대해 설명해주세요.</summary><br>

  3-way handshake는 TCP 통신에서 데이터를 전송하기 전에 클라이언트와 서버가 연결을 수립하는 과정으로, 아래 세 단계를 거칩니다.
  1. 클라이언트가 서버에게 연결 요청의 의미로 `SYN` 세그먼트를 전송합니다.
  2. 서버는 연결 요청에 대한 확인의 의미로 `SYN-ACK` 세그먼트를 응답합니다.
  3. 클라이언트는 서버의 응답에 대한 확인의 의미로 `ACK` 세그먼트를 서버로 보내며 최종적으로 연결이 수립됩니다.

  4-way handshake는 TCP 통신에서 연결을 종료하는 과정으로, 아래 네 단계를 거칩니다.
  1. 클라이언트가 서버에게 연결 종료 요청의 의미로 `FIN` 세그먼트를 전송합니다.
  2. 서버는 종료 요청에 대한 확인의 의미로 `ACK` 세그먼트를 클라이언트에게 응답합니다. (서버에서 아직 보낼 데이터가 남아있는 경우에도 `ACK` 세그먼트를 선응답합니다.)
  3. 서버는 모든 데이터 전송을 마친 후 서버쪽 연결 종료의 의미로 `FIN` 세그먼트를 클라이언트에게 전송합니다.
  4. 클라이언트는 서버쪽 연결 종료 확인의 의미로 `ACK` 세그먼트를 서버로 보내며 최종적으로 연결이 종료됩니다.
</details>
<details>
  <summary>HTTP와 HTTPS의 차이에 대해 설명해주세요.</summary><br>

  HTTP와 HTTPS는 웹에서 데이터를 주고받기 위한 프로토콜이며, <b>보안적인 측면</b>에서 차이가 있습니다.<br>

  <b>HTTP</b>는 애플리케이션 레벨의 요청-응답 기반 프로토콜로, 상태를 유지하지 않는 Stateless 프로토콜이며, TCP/IP 위에서 동작합니다.<br>
  평문 데이터를 전송하는 프로토콜이므로 클라이언트와 서버 간에 주고받는 모든 정보가 그대로 노출되어 보안에 취약합니다.<br>

  <b>HTTPS</b>는 HTTP에 <b>SSL/TLS 보안 계층</b>을 추가한 프로토콜로, 모든 데이터가 암호화되어 전송됩니다. 따라서 HTTP와 달리 중간에 가로채로 그 내용을 알 수 없습니다.
</details>
<details>
  <summary>SSL/TLS handshake에 대해 설명해주세요.</summary><br>

  SSL/TLS handshake는 클라이언트와 서버가 보안 연결을 설정하는 과정입니다.<br>
  1. 클라이언트가 서버에게 연결 요청을 보내면서 자신이 지원하는 TLS 버전, 사용 가능한 암호화 알고리즘 목록, 키 생성에 필요한 난수 등을 전송합니다.
  2. 서버는 클라이언트가 제안한 암호화 방식 중 하나를 선택하여 응답하고, 이후 서버의 공개키와 인증기관(CA, Certificate Authority)의 서명이 들어있는 인증서를 클라이언트에게 전송합니다.
  3. 클라이언트는 서버로부터 전달받은 인증서가 신뢰할 수 있는 인증서인지 검증합니다. 인증서는 CA의 개인키로 서명되어 있고, 클라이언트는 이를 운영체제나 브라우저에 미리 내장되어 있는 CA의 공개키를 통해 검증합니다.
  4. 이후 클라이언트는 서버의 공개키를 통해 통신에 사용할 비밀키를 암호화하여 서버에 전송하고, 서버는 이를 개인키로 확인합니다.
  5. 클라이언트와 서버 모두 비밀키와 난수를 조합하여 대칭키를 생성하고, 이후에 이루어지는 모든 통신은 이 대칭키로 암호화하여 전송합니다.

  > <b>SSL/TLS handshake에서 대칭키 암호화와 공개키 암호화를 복합적으로 사용하는 이유</b><br>
  > 대칭키 암호화와 공개키 암호화 방식을 복합적으로 활용하는 키를 <b>세션키</b>라고 합니다.<br>
  > 이를 통해 대칭키 암호화 방식의 보안 문제와, 공개키 암호화 방식의 성능 문제를 해결하고 각각의 장점만을 활용한 암호화 통신이 가능합니다.
</details>
<details>
  <summary><a>https://www.google.com</a>에 접속할 때 일어나는 일에 대해 설명해주세요.</summary><br>

  먼저 브라우저가 URL을 파싱해서 프로토콜과 도메인을 파악합니다.<br>

  이후 DNS 조회 과정이 일어나는데, `www.google.com`이라는 도메인 이름을 실제 IP 주소로 변환하기 위해 브라우저 캐시부터 시작해서 시스템 캐시, 로컬 DNS 서버를 거쳐서 최종적으로 IP 주소를 찾아냅니다.<br>

  IP 주소를 알아내면 3-way handshake 과정을 통해 해당 서버의 443번 포트와 TCP 연결을 설정하며, 추가로 HTTPS이기 때문에 보안 연결을 위한 TLS handshake를 진행하는데, 이때 암호화 방식을 협상하고 서버 인증서를 확인해서 보안 연결을 설정합니다.<br>

  보안 연결이 완료되면 HTTP 요청 메시지가 서버에 전송되며, 서버는 이에 대한 HTTP 응답 메시지를 내려줍니다.<br>

  서버로부터 전달된 HTTP 응답 메시지는 브라우저에서 받아서 최종적으로 화면에 렌더링 합니다.
</details>
<details>
  <summary>HTTP 메서드의 종류와 이것이 하는 역할에 대해 설명해주세요.</summary><br>

  HTTP 메서드는 <b>클라이언트가 서버에게 어떤 동작을 요청할지를 나타내는 방법</b>입니다.<br>

  <b>GET</b>은 서버로부터 리소스를 조회할 때 사용하며, 데이터를 가져오기만 하고 서버의 상태를 변경하지는 않습니다.<br>

  <b>POST</b>는 서버에 새로운 리소스를 생성할 때 주로 사용합니다.<br>

  <b>PUT</b>은 서버에 존재하는 리소스를 수정하거나 존재하지 않으면 생성합니다. 특정 리소스에 대한 전체 데이터를 새로운 내용으로 교체할 때 사용합니다.<br>

  <b>PATCH</b>는 특정 리소스의 일부분만을 수정할 때 사용합니다. PUT과 달리 전체가 아닌 특정 필드만 업데이트 하는 경우에 사용합니다.<br>

  <b>DELETE</b>는 서버의 리소스를 삭제할 때 사용합니다.<br>

  <b>HEAD</b>는 GET과 비슷하지만 응답 바디 없이 헤더 정보만 가져올 때 사용합니다.<br>

  <b>OPTIONS</b>는 서버가 특정 리소스에 대해 어떤 메서드들을 지원하는지 확인할 때 사용합니다.
</details>
<details>
  <summary>GET과 POST의 차이에 대해 설명해주세요.</summary><br>

  GET은 URL에 데이터가 노출되지만 POST는 요청 바디에 숨겨져서 전송된다는 차이가 있으며, 때문에 보안적인 측면에서 POST가 상대적으로 안전합니다.<br>
  
  또한 GET 요청에 대한 응답은 브라우저에 자동으로 캐싱되어, 같은 URL 요청 시 캐싱된 데이터를 사용할 수 있지만, POST 요청은 보통 서버의 상태를 변경하는 작업이기 때문에 브라우저가 기본적으로 캐싱하지 않아서 같은 URL 요청도 매번 새로운 요청을 보낸다는 차이가 있습니다.
</details>
<details>
  <summary>HTTP 상태 코드에 대해 설명해주세요.</summary><br>

  HTTP 상태 코드는 <b>클라이언트의 요청에 대한 서버의 응답 상태를 나타내는 3자리 숫자 코드</b>이며, 첫 번째 자리 숫자에 따라 5개의 그룹으로 나뉩니다.<br>

  <b>100번대</b>는 <b>정보성 응답</b>으로, 요청이 수신되어 처리 중임을 나타냅니다.<br>

  <b>200번대</b>는 <b>성공 응답</b>으로, 요청이 성공적으로 처리되었음을 의미합니다.<br>

  <b>300번대</b>는 <b>리다이렉션 응답</b>으로, 클라이언트가 요청한 리소스가 이동된 경우 이를 알리기 위한 코드입니다.<br>

  <b>400번대</b>는 <b>클라이언트 오류에 대한 응답</b>으로, 클라이언트 측의 잘못된 요청으로 인해 오류가 발생했음을 의미합니다.<br>

  <b>500번대</b>는 <b>서버 오류에 대한 응답</b>으로, 명백히 올바른 요청에 대해 서버 내부에서 오류가 발생했음을 의미합니다.
</details>

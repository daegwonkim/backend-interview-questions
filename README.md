<div align="center">
  <a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Black+Han+Sans&size=40&duration=3000&pause=1000&color=0EBB12&center=true&vCenter=true&width=450&lines=%EB%B0%B1%EC%97%94%EB%93%9C+%EA%B0%9C%EB%B0%9C%EC%9E%90+%EB%A9%B4%EC%A0%91+%EC%A7%88%EB%AC%B8+%EC%A0%95%EB%A6%AC" alt="Typing SVG" /></a>  
</div>

## 🎯 Introduction
백엔드 개발 면접을 준비하면서 정리한 질문과 답변 모음집입니다.  
CS, 프로그래밍 언어, 프레임워크, 데이터베이스, Web, 보안 관련 내용을 다룹니다.

## 📌 Index
- [CS](#-cs)
  - [운영체제](#운영체제)
  - [네트워크](#네트워크)
  - [자료구조/알고리즘](#자료구조알고리즘)
- [Programing Language](#-programing-language)
- [Framework](#-framework)
- [Database](#-database)
- [Web](#-web)
- [Security](#-security)

## 💡 Questions
### 🖥 CS
#### 운영체제
<details>
  <summary>프로세스와 스레드의 차이에 대해 설명해주세요.</summary><br>
  
  프로세스와 스레드는 운영체제에서 <b>실행의 단위</b>를 나타내는 개념입니다.<br>
  
  <b>프로세스</b>는 현재 실행 중인 프로그램을 의미하고, 각 프로세스는 독립적인 메모리 공간을 가지고 있으며, 다른 프로세스와 완전히 분리되어 있습니다.<br>
  
  <b>스레드</b>는 프로세스 내에서 실행되는 작업의 단위이며, 하나의 프로세스 안에 여러 개의 스레드가 있을 수 있습니다. 스레드들은 같은 프로세스의 메모리 공간(스택 영역 제외)을 공유합니다.<br>

  주요 차이점을 요약하면 다음과 같습니다.
  1. 프로세스는 독립적인 메모리 공간을 가지지만 스레드는 코드, 데이터, 힙 영역을 공유하고 스택 영역만 따로 갖습니다.<br>
  2. 프로세스 간에는 서로 통신을 통해서 자원을 공유하고 데이터를 주고받아야 하지만, 스레드는 공유 메모리를 통해서 쉽게 데이터를 공유할 수 있습니다.<br>
  3. 프로세스는 하나의 프로세스가 죽어도 다른 프로세스에 영향을 주지 않지만, 스레드는 하나에 문제가 생기면 해당 스레드를 포함하고 있는 전체 프로세스가 영향을 받을 수 있습니다.
</details>
<details>
  <summary>스레드를 사용하는 이유에 대해 설명해주세요.</summary><br>

  스레드를 사용하는 가장 큰 이유는 <b>동시성을 통한 성능 향상</b>입니다.<br>

  단일 스레드로는 하나의 작업이 끝날 때까지 다른 작업을 할 수 없지만, 멀티 스레드를 사용하면 여러 작업을 동시에 처리할 수 있어 전체적인 처리량이 증가합니다.<br>

  또 파일 읽기, 네트워크 통신, 데이터베이스 쿼리와 같은 I/O 작업은 시간이 오래 걸리는데, 이때 다른 스레드가 CPU를 사용해서 다른 작업을 처리할 수 있어서 <b>I/O 블로킹 문제</b>도 해결할 수 있습니다.
</details>
<details>
  <summary>스레드는 최대한 많이 생성해서 사용하면 좋을까요?</summary><br>

  Java에서 각 스레드는 기본적으로 1~2MB 정도의 스택 메모리를 할당받습니다. 이는 결코 적은 양이 아니기 때문에 스레드를 무작정 많이 생성하면 추후에 <b>메모리 부족 현상</b>이 발생할 수 있습니다.<br>

  또한 CPU 코어의 수는 한정적인데 스레드 수만 많아지면 OS가 계속해서 스레드를 교체하면서 실행해야 하므로, 이 과정에서 발생하는 <b>컨텍스트 스위칭 오버헤드</b>로 인해 성능이 나빠질 수 있습니다.<br>

  더불어 스레드를 만들고 없애는 작업 자체도 시스템 리소스를 많이 사용하기 때문에 <b>스레드 생성 및 소멸 비용</b>도 무시할 수 없습니다.<br>

  따라서 스레드를 사용할 때에는 <b>Thread Pool</b>을 사용해서 적절한 개수의 스레드를 미리 생성해두고 재사용하는 방식을 주로 사용합니다.<br>

  결국에는 적절한 수가 핵심이고, 모니터링을 통해 최적의 스레드 수를 찾아가는 것이 중요합니다.
</details>
<details>
  <summary>메모리 구조에 대해 설명해주세요.</summary><br>
  
  메모리 구조는 크게 코드 영역, 데이터 영역, 힙 영역, 스택 영역으로 구분됩니다.<br>
  
  <b>코드 영역</b>은 실행할 프로그램의 코드가 저장되는 영역으로, 컴파일된 기계어 명령어들이 저장됩니다.<br>
  사용자가 프로그램 실행 명령을 내리면 OS에서는 디스크에서 메모리의 코드 영역으로 실행 코드를 올리게 되고, CPU는 코드 영역에 저장된 명령어를 하나씩 실행하게 됩니다.<br>

  <b>데이터 영역</b>은 프로그램 실행에 필요한 전역 변수와 정적 변수가 저장되는 영역입니다.<br>
  
  <b>힙 영역</b>은 동적으로 할당되는 메모리 공간으로, `malloc()`이나 `new`와 같은 함수로 런타임에 메모리를 요청할 경우 사용됩니다.<br>
  
  <b>스택 영역</b>은 함수 호출과 관련된 데이터가 저장되는 공간으로, 매개 변수나 지역 변수와 같은 데이터가 스택 프레임의 형태로 저장됩니다.<br>
  함수가 호출되면 스택에 스택 프레임이 쌓이고, 함수가 종료되면 스택 프레임이 제거되는 방식으로 동작합니다.
</details>
<details>
  <summary>컨텍스트 스위칭에 대해 설명해주세요.</summary><br>

  컨텍스트 스위칭이란 <b>CPU가 현재 실행중인 프로세스나 스레드의 실행을 중단하고 다른 프로세스나 스레드로 전환하는 과정</b>을 말합니다.<br>

  현재 실행중인 프로세스의 상태를 <b>PCB(Process Control Block)</b>에 저장하고, 다음에 실행할 프로세스의 상태를 PCB에서 불러와서 CPU 레지스터에 복원하는 방식으로 동작합니다.<br>

  컨텍스트 스위칭이 발생하는 기준은 다음과 같습니다.
  1. 시분할 시스템에서 타임 슬라이스가 끝난 경우
  2. I/O 작업으로 프로세스가 대기 상태에 들어간 경우
  3. 우선순위가 높은 프로세스가 대기열에 들어선 경우
  4. 프로세스가 종료된 경우
</details>
<details>
  <summary>CPU 스케줄링 알고리즘에 대해 설명해주세요.</summary><br>

  CPU 스케줄링 알고리즘이란 <b>여러 프로세스가 CPU를 사용하려고 할 때 어떤 순서로 CPU를 할당할지 결정하는 방법</b>을 말합니다.<br>

  <b>FCFS(First Come First Served) 스케줄링 기법</b>은 먼저 도착한 프로세스부터 처리하는 가장 간단한 방식으로, 공정하지만 작업 시간이 긴 프로세스가 먼저 도착하면 뒤의 짧은 작업들이 오래 기다려야 하는 <b>콘보이 현상</b>이 발생할 수 있습니다.

  <b>SJF(Shortest Job First) 스케줄링 기법</b>은 실행 시간이 가장 짧은 프로세스부터 처리하는 방식으로, 평균 대기 시간을 최소화할 수 있지만, 프로세스의 실행 시간을 미리 알기가 어렵고 실행 시간이 긴 프로세스의 경우에는 계속 실행이 지연되어 <b>기아 현상</b>이 발생할 수 있습니다.<br>

  <b>Round Robin 스케줄링 기법</b>은 각 프로세스에게 동일한 시간 할당량(타임 슬라이스)을 주고 돌아가면서 실행시키는 방식으로, 응답시간이 좋고 공정하지만 타임 슬라이스가 너무 짧으면 <b>컨텍스트 스위칭 오버헤드</b>로 인해 성능에 문제가 생길 수 있습니다.<br>

  <b>우선순위 스케줄링 기법</b>은 각 프로세스에 우선순위를 부여해서 높은 우선순위의 프로세스부터 처리하는 방식으로, 중요한 작업을 먼저 처리할 수 있지만 낮은 우선순위 프로세스의 경우 계속 실행이 지연되어 <b>기아 현상</b>이 발생할 수 있습니다.<br>

  <b>다단계 피드백 큐 스케줄링 기법</b>은 여러 개의 큐를 두고 프로세스의 행동에 따라 우선순위를 동적으로 조정하는 방식으로, CPU 집약적인 프로세스는 낮은 우선순위로, I/O 집약적인 프로세스는 높은 우선순위로 관리하며 CPU 실행 효율성을 높이는 기법입니다.

  > <b>콘보이 현상</b><br>
  > 콘보이 현상이란 작업 시간이 긴 프로세스에 의해 다른 프로세스의 실행이 전부 늦춰지는 현상을 말합니다.<br>
  > FCFS 스케줄링은 <b>비선점형 스케줄링 방식</b>으로, I/O 작업으로 인해 프로세스가 대기 상태로 전환되거나 프로세스가 완전히 종료되기 전까지는 다른 프로세스를 실행할 수 없기 때문에 이러한 현상이 발생할 수 있습니다.

  > <b>기아 현상</b><br>
  > 기아 현상이란 특정 프로세스가 계속해서 자원을 할당받지 못해 무한정 기다리게 되는 상황을 말합니다.<br>
  > 즉, SJF나 우선순위 스케줄링 방식에서 우선순위가 높은 프로세스들이 계속 들어오면서 우선순위가 낮은 프로세스는 영원히 실행되지 못하는 것을 의미하며, 이에 대한 가장 일반적인 해결책은 프로세스가 오래 기다릴수록 우선순위를 점진적으로 높여주는 <b>에이징(aging) 기법</b>을 사용하는 것입니다.
</details>
<details>
  <summary>선점형 스케줄링과 비선점형 스케줄링의 차이에 대해 설명해주세요.</summary><br>

  선점형 스케줄링과 비선점형 스케줄링은 <b>현재 실행중인 프로세스로부터 CPU를 강제로 빼앗을 수 있는지에 대한 개념</b>을 말합니다.<br>

  <b>비선점형 스케줄링</b>에서는 한 번 CPU를 할당받은 프로세스는 작업이 완료되거나 자발적으로 CPU 반납하지 않는 이상 계속 실행됩니다.<br>
  즉, 운영체제가 강제로 CPU를 빼앗을 수 없으며, 대표적인 예로 FCFS, SJF 스케줄링이 있습니다.<br>
  비선점형 스케줄링은 구현이 간단하고 컨텍스트 스위칭 오버헤드가 적지만, 작업 시간이 긴 프로세스가 CPU를 독점할 경우 응답 시간이 나빠질 수 있습니다.<br>

  <b>선점형 스케줄링</b>에서는 운영체제가 필요에 따라 현재 실행중인 프로세스로부터 CPU를 강제로 빼앗을 수 있습니다.<br>
  타임 슬라이스가 끝나거나 더 높은 우선순위 프로세스가 나타나면 현재 프로세스를 중단시키고 다른 프로세스를 실행하는 방식으로, 대표적인 예로 Round Robin이나 우선순위 스케줄링이 있습니다.<br>
  선점형 스케줄링은 응답 시간이 좋고 공정하지만, 컨텍스트 스위칭 오버헤드가 커질 수 있습니다.
</details>
<details>
  <summary>동기와 비동기의 차이에 대해 설명해주세요.</summary><br>

  동기와 비동기는 <b>작업의 실행 방식과 결과를 기다리는 방법에 대한 개념</b>을 말합니다.<br>

  <b>동기(Synchronous)</b>란 작업을 순차적으로 실행하는 방식으로, 하나의 작업이 완전이 끝날 때까지 기다렸다가 다음 작업을 실행합니다.<br>
  동기 방식은 코드가 직관적이고 이해하기 쉽지만, 느린 작업이 포함되어 있으면 전체적인 성능에 악영향을 미칠 수 있다는 특징을 갖고 있습니다.<br>

  <b>비동기(Asynchronous)</b>란 작업을 시작한 후 해당 작업에 대한 완료를 기다리지 않고 또 다른 작업 요청을 받아서 처리하는 방식으로, 나중에 작업이 완료된 것이 감지되면 그때 결과를 처리합니다.<br>
  비동기 방식은 효율적이고 응답성이 좋지만, 코드가 복잡해지고 디버깅이 어려워질 수 있다는 특징을 갖고 있습니다.
</details>
<details>
  <summary>Blocking I/O와 Non-blocking I/O의 차이에 대해 설명해주세요.</summary><br>

  Blocking I/O와 Non-blocking I/O는 <b>입출력 작업을 처리하는 방식에 대한 개념</b>을 말합니다.<br>

  <b>Blocking I/O</b>는 I/O 작업을 요청한 후 그 작업이 완료될 때까지 스레드가 대기하는 방식으로, 예를 들어 파일을 읽는 함수를 호출하면 파일 읽기가 완전히 끝날 때까지 해당 스레드는 다른 작업을 수행할 수 없게 됩니다.<br>
  코드는 간단하지만 효율성이 떨어진다는 특징을 갖고 있습니다.<br>

  <b>Non-blocking I/O</b>는 I/O 작업을 요청한 후 스레드가 커널로부터 바로 제어권을 반환 받아서 다른 작업을 처리할 수 있는 방식으로, 이후 polling이나 커널의 system call을 통해 작업이 완료되었음을 확인합니다.<br>
  Blocking 방식에 비해 효율적이지만, polling 방식을 사용할 경우 CPU 사용량이 늘어날 수 있습니다.
</details>
<details>
  <summary>멀티 스레드 프로그래밍에 대해 설명해주세요.</summary><br>

  멀티 스레드 프로그래밍이란 <b>하나의 프로세스 내에서 여러 개의 스레드를 생성하여 작업을 병렬로 처리하는 프로그래밍 기법</b>입니다.<br>

  이때 각 스레드는 같은 프로세스의 메모리 공간(스택 영역 제외)을 공유하며, 독립적인 실행 흐름을 갖습니다.<br>

  멀티 스레드를 사용하면 CPU 코어를 효율적으로 활용할 수 있고, I/O 작업 중에도 다른 스레드가 작업을 계속할 수 있어서 전체적인 처리량이 늘어납니다.<br>

  다만, 여러 스레드가 공유 데이터에 동시에 접근하는 경우에는 예상치 못한 결과가 나오거나(Race Condition), 교착상태가 발생할 수도 있습니다.<br>

  따라서 멀티 스레드 환경에서는 뮤텍스, 세마포어 같은 동기화 도구를 사용해서 임계 영역에는 한 번에 하나의 스레드만 접근할 수 있도록 동기화 처리를 하는 것이 중요합니다.
</details>
<details>
  <summary>멀티 스레드 환경에서의 동기화 기법에 대해 설명해주세요.</summary><br>

  멀티 스레드 환경에서 공유 자원에 대한 접근을 제어해서 데이터의 일관성을 보장하는 방법으로 사용되는 도구는 크게 3가지가 있습니다.<br>

  <b>뮤텍스(Mutex)</b>는 가장 기본적인 동기화 도구로, <b>한 번에 하나의 스레드</b>만 임계 영역에 접근할 수 있도록 합니다.<br>
  즉, 임계 영역에 진입할 수 있는 열쇠가 하나 뿐이며, 특정 스레드가 락을 획득하면 다른 스레드들은 락이 해제될 때까지 기다려야 합니다.<br>

  <b>세마포어는(Semaphore)</b>는 뮤텍스를 일반화한 개념으로, <b>동시에 접근할 수 있는 스레드의 개수를 제한</b>하는 방식입니다.<br>
  즉, 정해진 카운트에 따라 임계 영역에 동시에 접근할 수 있는 스레드의 개수가 정해지며, 뮤텍스와 마찬가지로 락을 획득하고 해제하는 작업을 통해 동기화가 이루어집니다.<br>

  <b>모니터(Monitor)</b>는 뮤텍스에 <b>조건 변수</b>를 추가한 동기화 도구로, 조건 변수란 특정 조건이 참이 될 때까지 스레드를 대기시키는 도구를 말합니다. (주로 생산자-소비자 문제에서 버퍼가 비어있을 때 소비자를 기다리게 하는 용도로 많이 사용됨)<br>
  따라서 모니터는 단순한 락 획득/해제 뿐만 아니라 조건 변수를 통한 조건 기반 대기와 통지 매커니즘을 제공하여 더 정교한 제어가 가능합니다.
</details>
<details>
  <summary>레이스 컨디션에 대해 설명해주세요.</summary><br>

  레이스 컨디션(Race Condition)이란 <b>둘 이상의 프로세스나 스레드가 공유 자원에 동시에 접근하여 변경하려고 할 때, 실행 순서에 따라 예상치 못한 결과가 나오는 현상</b>을 말합니다.<br>

  레이스 컨디션의 가장 큰 문제는 항상 발생하는 것이 아니라 타이밍에 따라 간헐적으로 발생한다는 점으로, 찾기도 어렵고 재현하기도 힘들어서 멀티 스레드 환경에서 가장 조심해야하는 부분입니다.
</details>
<details>
  <summary>교착상태에 대해 설명해주세요.</summary><br>

  교착상태(Deadlock)란 <b>두 개 이상의 프로세스나 스레드가 서로가 가진 자원을 기다리면서 무한정 대기하는 상태</b>를 말합니다.<br>

  교착 상태는 프로세스나 스레드가 서로 자원을 점유하려고 하는 과정에서 아래 네 가지 필요조건이 동시에 충족될 경우 발생합니다.
  - <b>상호배제</b>: 자원은 한 번에 하나의 프로세스만 사용할 수 있다.
  - <b>비선점</b>: 다른 프로세스의 자원을 강제로 빼앗을 수 없다.
  - <b>점유와 대기</b>: 자원을 할당받은 상태에서 또 다른 자원을 기다리는 상태
  - <b>순환 대기</b>: 프로세스들이 원형으로 서로의 자원을 기다리는 상태

  교착상태를 해결하기 위한 방법으로는 크게 3가지가 있습니다.
  - <b>교착상태 예방</b>: 교착상태가 발생하는 조건 중 하나라도 충족하지 않도록 설계하는 방법
  - <b>교착상태 회피</b>: 교착 상태가 발생할 가능성을 배제하지 않고 자원을 적당히 할당하다가 교착상태의 위험이 있을 때에는 자원을 할당하지 않는 방법. 즉, 안전한 상태에서만 자원을 할당하는 방법으로, 대표적으로는 <b>은행원 알고리즘(Banker's Algorithm)</b>이 있다.
  - <b>검출 후 회복</b>: 자원을 제약 없이 할당하다가 교착상태가 발생하면 해결하는 방법
</details>
<details>
  <summary>가상 메모리에 대해 설명해주세요.</summary><br>

  가상 메모리란 <b>실행하고자 하는 프로그램의 일부만 메모리에 적재하는 메모리 관리 기법</b>입니다.<br>

  이를 통해 실제 메모리 크기보다 큰 프로그램도 실행할 수 있고, 여러 프로세스가 메모리를 효율적으로 공유할 수 있습니다.<br>

  주로 프로세스의 논리 주소 공간과 메모리의 물리 주소 공간을 페이지와 프레임이라고 하는 일정한 단위로 나누어서 관리하는 <b>페이징 기법</b>을 사용하여 구현하며, 운영체제는 물리 메모리와 디스크 간에 페이지를 교체하면서 가상 메모리 시스템을 구현합니다.<br>

  이때 보편적으로 사용되는 페이지 교체 알고리즘은 <b>LRU(Least Recently Used)</b> 알고리즘으로, 이는 실제 메모리 상의 페이지들 중에서 가장 오랫동안 사용되지 않은 페이지를 교체하는 방식입니다.

  > <b>논리 주소와 물리 주소</b><br>
  > 논리 주소와 물리 주소는 메모리 관리 측면에서 사용되는 두 가지의 다른 주소 체계입니다.<br>
  > <b>논리 주소(가상 주소)</b>는 프로세스가 바라보는 논리적인 주소로, 프로세스 입장에서는 항상 0번지부터 시작하는 연속된 메모리 공간을 가진 것처럼 보입니다.<br>
  > <b>물리 주소</b>는 하드웨어가 실제로 접근하는 메모리의 물리적인 주소를 말합니다.<br>
  > CPU는 논리 주소로 메모리에 접근하며, 이 논리 주소는 <b>MMU(Memory Management Unit)</b>에 의해 물리 주소로 변환되어 실제 메모리 주소에 접근하게 됩니다.

  > <b>페이지 폴트(Page Fault)</b><br>
  > 페이지 폴트란 <b>프로세스가 접근하려는 페이지가 가상 메모리에는 존재하지만, 물리 메모리에는 존재하는 않을 때 발생하는 예외 상황</b>을 말합니다.<br>
  > 페이지 폴트가 발생하면 운영체제는 디스크에서 해당 페이지를 찾아서 메모리로 가져오는 과정을 거치게 되며, 이때 디스크 I/O가 발생하므로 페이지 폴트가 자주 발생하는 경우 시스템 성능이 크게 떨어질 수 있습니다.
</details>
<details>
  <summary>캐시에 대해 설명해주세요.</summary><br>

  캐시(Cache)란 <b>자주 사용되는 데이터를 가까운 저장소에 임시로 보관해서 시스템의 성능을 향상시키는 기법</b>입니다.<br>

  캐시 저장소는 CPU와 가깝기 때문에 메모리나 디스크에서 데이터를 읽는 것보다 훨씬 빨라, 자주 사용하는 데이터의 경우에는 캐시에 이를 저장하고 읽는 방식으로 성능을 높일 수 있습니다.<br>

  캐시에 저장될 데이터는 아래와 같은 기준에 따라 결정됩니다.
  - <b>시간 지역성</b>: 어떤 데이터가 최근에 사용되었다면, 가까운 미래에 다시 사용될 가능성이 높다는 원리
  - <b>공간 지역성</b>: 특정 데이터에 접근할 때, 그 데이터와 메모리상에서 인접한 다른 데이터도 함께 접근될 가능성이 높다는 원리
</details><br>

#### 네트워크
<details>
  <summary>OSI 7 계층에 대해 설명해주세요.</summary><br>

  OSI 7 계층은 네트워크 통신 과정을 7개의 단계로 나누어서 표준화한 네트워크 참조 모델입니다.<br>

  <b>1계층은 물리 계층(Physical Layer)</b>으로, 0과 1의 비트를 전기 신호로 변환하여 전송하는 계층입니다.<br>
  물리 계층에는 주소 개념이 없으며 송수신만 이루어질 뿐 전송되는 데이터에 대해 어떠한 조작이나 판단도 하지 않습니다.<br>
  케이블, 허브, 리피터 같은 물리적 장비들이 여기에 해당합니다.<br>

  <b>2계층은 데이터 링크 계층(Data Link Layer)</b>으로, 같은 네트워크(LAN) 내에 있는 호스트 간의 데이터 전송을 담당합니다.<br>
  데이터링크 계층에는 주소 개념이 있으며, MAC 주소를 사용해서 프레임 단위로 데이터를 전송합니다. 스위치, 브리지가 이 계층에서 동작합니다.<br>
  
  <b>3계층은 네트워크 계층(Network Layer)</b>으로, LAN을 넘어서 서로 다른 네트워크 간의 경로를 찾아 통신할 수 있도록 하는 계층입니다.<br>
  여기에서는 IP 주소를 사용해서 패킷을 목적지까지 라우팅하며, 라우터가 이 계층에서 작동하고, 대표적인 프로토콜로 IP 프로토콜, ARP 프로토콜이 있습니다.<br>
  
  <b>4계층은 전송 계층(Transport Layer)</b>으로, 애플리케이션 간 데이터 전송을 담당합니다.<br>
  포트 번호를 사용해서 네트워크 상의 애플리케이션을 식별하여 어디에 데이터를 전달할지 결정하며, TCP와 UDP가 이 계층의 대표적인 프로토콜입니다. <br>
  
  <b>5계층은 세션 계층(Session Layer)</b>으로, 애플리케이션 간의 통신에서 세션을 관리하는 계층이며, 연결 설정, 유지, 종료 및 동기화 기능을 제공합니다.<br>
  
  <b>6계층은 표현 계층(Presentation Layer)</b>으로, 애플리케이션 간의 통신에서 메시지 포맷을 관리하는 계층이며, 암호화, 압축, 인코딩 같은 작업을 수행합니다.
  
  <b>7계층은 응용 계층(Application Layer)</b>으로, 사용자와 직접 상호작용하는 계층이며, 애플리케이션 목적에 맞는 통신 방법을 제공합니다.<br>
  HTTP, FTP, SMTP, DNS 같은 프로토콜들이 이 계층에서 동작합니다.<br>
  
  이렇계 네트워크를 설계하면, 각 계층이 독립적으로 동작하여 하나의 계층에 문제가 생겨도 다른 계층에 영향을 주지 않고, 네트워크 문제가 발생했을 때 이를 체계적으로 분석할 수 있습니다.
</details>
<details>
  <summary>TCP와 UDP에 대해 설명해주세요.</summary><br>

  TCP와 UDP는 전송 계층에서 사용되는 두 가지 프로토콜로, <b>데이터 전송 방식</b>에서 차이가 있습니다.<br>

  <b>TCP(Transmission Control Protocol)</b>는 <b>연결 지향적 프로토콜</b>로, 데이터를 전송하기 전에 먼저 연결을 설정합니다.<br>
  TCP는 3-way handshake를 통해 연결을 맺고, 4-way handshake로 연결을 종료합니다.<br>
  TCP의 가장 큰 특징은 신뢰성으로, 데이터가 순차적으로 전달되는 것을 보장하고, 오류 제어 기능을 통해 패킷이 손실되면 재전송하여 모든 데이터가 정확하게 도작하도록 보장합니다. 또한 흐름 제어와 혼잡 제어 기능을 통해 네트워크 상황에 맞게 전송 속도를 조절할 수 있습니다.<br>

  <b>UDP(User Datagram Protocol)</b>는 <b>비연결 지향적 프로토콜</b>로, 연결 설정 과정 없이 바로 데이터를 전송합니다.<br>
  때문에 속도가 빠르고 오버헤드가 적지만, 신뢰성은 보장하지 않습니다. 즉, 패킷이 순서대로 도착하지 않을 수 있고, 손실될 수도 있습니다.<br>

  따라서 TCP는 이메일, 파일 전송처럼 데이터의 정확성이 중요한 곳에 주로 사용되고, UDP는 실시간 게임이나 동영상 스트리밍처럼 속도가 중요하고 약산의 손실은 허용할 수 있는 경우에 주로 사용됩니다.
</details>
<details>
  <summary>TCP의 3-way handshake, 4-way handshake에 대해 설명해주세요.</summary><br>

  <b>3-way handshake</b>는 TCP 통신에서 데이터를 전송하기 전에 클라이언트와 서버가 연결을 수립하는 과정으로, 아래 세 단계를 거칩니다.
  1. 클라이언트가 서버에게 연결 요청의 의미로 `SYN` 세그먼트를 전송합니다.
  2. 서버는 연결 요청에 대한 확인의 의미로 `SYN-ACK` 세그먼트를 응답합니다.
  3. 클라이언트는 서버의 응답에 대한 확인의 의미로 `ACK` 세그먼트를 서버로 보내며 최종적으로 연결이 수립됩니다.

  <b>4-way handshake</b>는 TCP 통신에서 연결을 종료하는 과정으로, 아래 네 단계를 거칩니다.
  1. 클라이언트가 서버에게 연결 종료 요청의 의미로 `FIN` 세그먼트를 전송합니다.
  2. 서버는 종료 요청에 대한 확인의 의미로 `ACK` 세그먼트를 클라이언트에게 응답합니다. (서버에서 아직 보낼 데이터가 남아있는 경우에도 `ACK` 세그먼트를 선응답합니다.)
  3. 서버는 모든 데이터 전송을 마친 후 서버쪽 연결 종료의 의미로 `FIN` 세그먼트를 클라이언트에게 전송합니다.
  4. 클라이언트는 서버쪽 연결 종료 확인의 의미로 `ACK` 세그먼트를 서버로 보내며 최종적으로 연결이 종료됩니다.
</details>
<details>
  <summary>HTTP와 HTTPS의 차이에 대해 설명해주세요.</summary><br>

  HTTP와 HTTPS는 웹에서 데이터를 주고받기 위한 프로토콜이며, <b>보안적인 측면</b>에서 차이가 있습니다.<br>

  <b>HTTP</b>는 애플리케이션 레벨의 요청-응답 기반 프로토콜로, 상태를 유지하지 않는 Stateless 프로토콜이며, TCP/IP 위에서 동작합니다.<br>
  평문 데이터를 전송하는 프로토콜이므로 클라이언트와 서버 간에 주고받는 모든 정보가 그대로 노출되어 보안에 취약합니다.<br>

  <b>HTTPS</b>는 HTTP에 <b>SSL/TLS 보안 계층</b>을 추가한 프로토콜로, 모든 데이터가 암호화되어 전송됩니다. 따라서 HTTP와 달리 중간에 가로채로 그 내용을 알 수 없습니다.
</details>
<details>
  <summary>SSL/TLS handshake에 대해 설명해주세요.</summary><br>

  SSL/TLS handshake는 클라이언트와 서버가 보안 연결을 설정하는 과정입니다.<br>
  1. 클라이언트가 서버에게 연결 요청을 보내면서 자신이 지원하는 TLS 버전, 사용 가능한 암호화 알고리즘 목록, 키 생성에 필요한 난수 등을 전송합니다.
  2. 서버는 클라이언트가 제안한 암호화 방식 중 하나를 선택하여 응답하고, 이후 서버의 공개키와 인증기관(CA, Certificate Authority)의 서명이 들어있는 인증서를 클라이언트에게 전송합니다.
  3. 클라이언트는 서버로부터 전달받은 인증서가 신뢰할 수 있는 인증서인지 검증합니다. 인증서는 CA의 개인키로 서명되어 있고, 클라이언트는 이를 운영체제나 브라우저에 미리 내장되어 있는 CA의 공개키를 통해 검증합니다.
  4. 이후 클라이언트는 서버의 공개키를 통해 통신에 사용할 비밀키를 암호화하여 서버에 전송하고, 서버는 이를 개인키로 확인합니다.
  5. 클라이언트와 서버 모두 비밀키와 난수를 조합하여 대칭키를 생성하고, 이후에 이루어지는 모든 통신은 이 대칭키로 암호화하여 전송합니다.

  > <b>SSL/TLS handshake에서 대칭키 암호화와 공개키 암호화를 복합적으로 사용하는 이유</b><br>
  > 대칭키 암호화와 공개키 암호화 방식을 복합적으로 활용하는 키를 <b>세션키</b>라고 합니다.<br>
  > 이를 통해 대칭키 암호화 방식의 보안 문제와, 공개키 암호화 방식의 성능 문제를 해결하고 각각의 장점만을 활용한 암호화 통신이 가능합니다.
</details>
<details>
  <summary><a>https://www.google.com</a>에 접속할 때 일어나는 일에 대해 설명해주세요.</summary><br>

  먼저 브라우저가 URL을 파싱해서 프로토콜과 도메인을 파악합니다.<br>

  이후 DNS 조회 과정이 일어나는데, `www.google.com`이라는 도메인 이름을 실제 IP 주소로 변환하기 위해 브라우저 캐시부터 시작해서 시스템 캐시, 로컬 DNS 서버를 거쳐서 최종적으로 IP 주소를 찾아냅니다.<br>

  IP 주소를 알아내면 3-way handshake 과정을 통해 해당 서버의 443번 포트와 TCP 연결을 설정하며, 추가로 HTTPS이기 때문에 보안 연결을 위한 TLS handshake를 진행하는데, 이때 암호화 방식을 협상하고 서버 인증서를 확인해서 보안 연결을 설정합니다.<br>

  보안 연결이 완료되면 HTTP 요청 메시지가 서버에 전송되며, 서버는 이에 대한 HTTP 응답 메시지를 내려줍니다.<br>

  서버로부터 전달된 HTTP 응답 메시지는 브라우저에서 받아서 최종적으로 화면에 렌더링 합니다.
</details>
<details>
  <summary>HTTP 메서드의 종류와 이것이 하는 역할에 대해 설명해주세요.</summary><br>

  HTTP 메서드는 <b>클라이언트가 서버에게 어떤 동작을 요청할지를 나타내는 방법</b>입니다.<br>

  <b>GET</b>은 서버로부터 리소스를 조회할 때 사용하며, 데이터를 가져오기만 하고 서버의 상태를 변경하지는 않습니다.<br>

  <b>POST</b>는 서버에 새로운 리소스를 생성할 때 주로 사용합니다.<br>

  <b>PUT</b>은 서버에 존재하는 리소스를 수정하거나 존재하지 않으면 생성합니다. 특정 리소스에 대한 전체 데이터를 새로운 내용으로 교체할 때 사용합니다.<br>

  <b>PATCH</b>는 특정 리소스의 일부분만을 수정할 때 사용합니다. PUT과 달리 전체가 아닌 특정 필드만 업데이트 하는 경우에 사용합니다.<br>

  <b>DELETE</b>는 서버의 리소스를 삭제할 때 사용합니다.<br>

  <b>HEAD</b>는 GET과 비슷하지만 응답 바디 없이 헤더 정보만 가져올 때 사용합니다.<br>

  <b>OPTIONS</b>는 서버가 특정 리소스에 대해 어떤 메서드들을 지원하는지 확인할 때 사용합니다.
</details>
<details>
  <summary>GET과 POST의 차이에 대해 설명해주세요.</summary><br>

  GET은 URL에 데이터가 노출되지만 POST는 요청 바디에 숨겨져서 전송된다는 차이가 있으며, 때문에 보안적인 측면에서 POST가 상대적으로 안전합니다.<br>
  
  또한 GET 요청에 대한 응답은 브라우저에 자동으로 캐싱되어, 같은 URL 요청 시 캐싱된 데이터를 사용할 수 있지만, POST 요청은 보통 서버의 상태를 변경하는 작업이기 때문에 브라우저가 기본적으로 캐싱하지 않아서 같은 URL 요청도 매번 새로운 요청을 보낸다는 차이가 있습니다.
</details>
<details>
  <summary>HTTP 상태 코드에 대해 설명해주세요.</summary><br>

  HTTP 상태 코드는 <b>클라이언트의 요청에 대한 서버의 응답 상태를 나타내는 3자리 숫자 코드</b>이며, 첫 번째 자리 숫자에 따라 5개의 그룹으로 나뉩니다.<br>

  <b>100번대</b>는 <b>정보성 응답</b>으로, 요청이 수신되어 처리 중임을 나타냅니다.<br>

  <b>200번대</b>는 <b>성공 응답</b>으로, 요청이 성공적으로 처리되었음을 의미합니다.<br>

  <b>300번대</b>는 <b>리다이렉션 응답</b>으로, 클라이언트가 요청한 리소스가 이동된 경우 이를 알리기 위한 코드입니다.<br>

  <b>400번대</b>는 <b>클라이언트 오류에 대한 응답</b>으로, 클라이언트 측의 잘못된 요청으로 인해 오류가 발생했음을 의미합니다.<br>

  <b>500번대</b>는 <b>서버 오류에 대한 응답</b>으로, 명백히 올바른 요청에 대해 서버 내부에서 오류가 발생했음을 의미합니다.
</details><br>

#### 자료구조/알고리즘
<details>
  <summary>스택과 큐에 대해 설명해주세요.</summary><br>

  <b>스택(Stack)</b>은 LIFO(Last In First Out) 구조로, 마지막에 들어온 데이터가 가장 먼저 나가는 방식의 자료구조입니다.<br>
  주로 함수 호출 관리, 브라우저의 뒤로가기 기능, 수식의 괄호 검사, DFS 알고리즘 등에서 사용하며, 시간 복잡도는 모든 기본 연산이 O(1)입니다.<br>

  <b>큐(Queue)</b>는 FIFO(First In First Out) 구조로, 먼저 들어온 데이터가 먼저 나가는 방식의 자료구조입니다.<br>
  주로 프로세스 스케줄링, I/O 작업 대기열, BFS 알고리즘, 버퍼링 등에 사용되며, 시간 복잡도는 모든 기본 연산이 O(1)입니다.
</details>
<details>
  <summary>트리와 힙에 대해 설명해주세요.</summary><br>

  <b>트리(Tree)</b>는 계층적 구조를 가진 비선형 자료구조로, 노드들이 부모-자식 관계로 연결되어 있습니다.<br>
  최상위 루트 노드부터 시작해서 각 노드가 여러 자식 노드를 가질 수 있으며, 사이클이 존재하지 않습니다.<br>
  주로 파일 시스템, DOM 구조, 의사결정 트리 등과 같이 계층적 데이터 표현이 필요한 경우에 사용됩니다.<br>

  <b>힙(Heap)</b>은 완전 이진 트리 기반의 자료구조로, 부모와 자식 간에 특정한 순서 관계를 만족합니다.<br>
  <b>최대힙</b>은 부모 노드의 값이 자식 노드의 값보다 항상 크거나 같고, <b>최소힙</b>은 부모 노드의 값이 자식 노드의 값보다 항상 작거나 같습니다.<br>
  힙의 핵심 특징은 루트 노드가 최대힙에서는 항상 최댓값을 의미하고, 최소힙에서는 항상 최솟값을 의미한다는 점이며, 이러한 특징 때문에 주로 최댓값/최솟값을 빠르게 찾아야 하는 상황에서 유용하게 사용됩니다.<br>
  힙은 새로운 노드의 삽입과 삭제 시 힙의 속성을 유지하기 위해 heapify 과정을 거치며, 이때의 시간 복잡도는 O(log n)입니다.

  > <b>완전 이진 트리(Complete Binary Tree)</b><br>
  > 완전 이진 트리는 다음 두 가지 조건을 충족하는 트리를 의미합니다.<br>
  > 첫째, 마지막 레벨을 제외하고 모든 노드가 채워져 있어야 합니다. 마지막 레벨의 노드는 다 채워져 있을 수도 있고 아닐 수도 있습니다.<br>
  > 둘째, 노드는 왼쪽에서 오른쪽 방향으로 채워져야 합니다.
</details>
<details>
  <summary>배열과 연결 리스트의 차이에 대해 설명해주세요.</summary><br>

  <b>배열(Array)</b>은 메모리상에서 연속적인 공간에 동일한 타입의 데이터를 저장하는 자료구조입니다.<br>
  인덱스를 통해 직접 접근이 가능하여 임의 접근(Random Access)이 O(1) 시간에 이루어집니다.<br>
  장점으로는 빠른 접근 속도와 메모리 효율성이 있고, 단점으로는 크기가 고정되어 있어 동적 할당이 어렵고, 중간 삽입/삭제 시 O(n)의 시간이 소요됩니다.<br>

  <b>연결 리스트(Linked List)</b>는 노드들이 포인터로 연결된 자료구조입니다.<br>
  각 노드는 데이터와 다음 노드를 가리키는 포인터를 가지고 있어, 메모리상에서 연속적이지 않은 위치에 저장될 수 있습니다.<br>
  장점은 동적으로 크기 조절이 가능하고, 삽입/삭제가 O(1) 시간에 가능하다는 점이며, 단점으로는 순차 접근(Sequential Access)만 가능하여 특정 위치에 접근하려면 O(n) 시간이 걸리고, 포인터를 위한 추가적인 메모리가 필요하다는 점이 있습니다.<br>
  
  핵심 차이점은 <b>메모리 구조(연속 vs 비연속)</b>, <b>접근 방식(임의 vs 순차)</b>, <b>크기 변경 가능성</b>, 그리고 <b>삽입/삭제와 접근의 시간복잡도 트레이드오프</b>입니다.<br>
  빈번한 접근이 필요하면 배열을, 빈번한 삽입/삭제가 필요하면 연결 리스트를 선택하는 것이 일반적입니다.
</details>
<details>
  <summary>해시 테이블에 대해 설명해주세요.</summary><br>

  <b>해시 테이블(Hash Table)</b>은 <b>키-값(Key-Value) 쌍으로 데이터를 저장하는 자료구조</b>로, <b>해시 함수</b>를 사용해서 키를 버킷(Bucket)의 인덱스(Index)로 변환하여 데이터에 빠르게 접근할 수 있도록 합니다.<br>

  이상적인 경우 삽입, 삭제, 검색 모두 O(1)의 시간이 소요됩니다. 하지만 <b>해시 충돌</b>이 많이 발생하면 최악의 경우 O(n)까지 늘어날 수 있습니다.<br>

  해시 충돌은 서로 다른 키가 같은 해시값을 가지는 경우에 발생하며, 이를 해결하기 위해서는 같은 인덱스에 연결 리스트로 여러 값을 저장하는 <b>체이닝 방식</b>을 사용하거나, 다른 빈 공간을 찾아서 저장하는 <b>개방 주소법</b>을 사용하여 해결할 수 있습니다.<br>

  해시 테이블은 데이터베이스 인덱싱, 프로그래밍 언어의 Dictionary나 Map 자료형 등에 사용됩니다.
</details>
<details>
  <summary>우선순위 큐에 대해 설명해주세요.</summary><br>

  <b>우선순위 큐(Priority Queue)</b>는 각 원소에 우선순위가 있어서, <b>들어온 순서와 관계없이 우선순위가 높은 원소가 먼저 처리되는 자료구조</b>입니다.<br>
  즉, 우선순위가 가장 높은 데이터를 먼저 꺼내기 위해 고안된 자료구조로, 이를 구현하기 위해서는 일반적으로 <b>힙(Heap)</b>을 사용합니다.<br>

  힙은 <b>완전 이진 트리</b>를 기반으로 구현되었기 때문에 우선순위 큐를 힙으로 구현하면 삽입과 삭제가 모두 <b>O(log n)</b> 시간에 처리할 수 있습니다.<br>
  배열이나 연결 리스트로도 구현 가능하지만 이 둘은 선형 자료구조이며, 삽입 또는 삭제 연산을 위한 시간 복잡도가 O(n)이므로, 비효율적입니다.<br>

  우선순위 큐는 운영체제의 프로세스 스케줄링, 최단 경로 알고리즘 등에서 주로 사용됩니다.
</details>
<details>
  <summary>이진 탐색 트리에 대해 설명해주세요.</summary><br>

  <b>이진 탐색 트리(Binary Search Tree)</b>는 이진 트리 구조에서 <b>특별한 규칙</b>이 추가된 자료구조입니다.<br>

  이진 탐색 트리에서 <b>각 노드의 왼쪽 자식은 현재 노드보다 작은 값, 오른쪽 자식은 현재 노드보다 큰 값</b>을 가지며, 이 규칙은 모든 노드에 적용됩니다.<br>

  시간 복잡도는 균형 잡힌 트리에서는 O(log n)이지만, 노드가 한쪽으로 치우친 형태이면 최악의 경우 O(n)까지 늘어날 수 있습니다.
</details>
<details>
  <summary>RB 트리에 대해 설명해주세요.</summary><br>

  <b>RB(Red-Black)</b> 트리는 <b>자가 균형 이진 탐색 트리</b>의 한 종류로, BST의 문제점인 <b>편향된 트리</b>를 해결하기 위해 각 노드에 색깔(빨간색 또는 검은색)을 부여하고, “루트 노드와 리프 노드는 항상 검은색이어야 한다”, “빨간색 노드의 자식은 반드시 검은색이어야 한다”와 같은 특별한 규칙들을 적용한 자료구조입니다.<br>

  RB 트리는 이러한 규칙을 깨지 않기 위해 삽입이나 삭제 시에 색깔 변경이나 회전 연산을 통해 다시 균형을 맞추며, 트리의 높이가 항상 균형되도록 유지합니다.
</details>
<details>
  <summary>Big-O 표기법의 시간 복잡도 크기 순서를 말해주세요.</summary><br>

  O(1) < O(log N) < O(N) < O(N log N) < O(N^2) < O(2^N) < O(N!)
</details>
<details>
  <summary>주요 정렬 방식에 대해 설명해주세요.</summary><br>

  <b>버블 정렬</b>은 첫 번째 요소부터 마지막 요소까지 순회하며, 서로 인접한 두 원소를 비교해가며 정렬하는 알고리즘으로, 가장 간단하지만 <b>O(n²)</b>의 시간복잡도로 비효율적입니다. 따라서 실제로는 거의 사용하지 않습니다.

  <b>선택 정렬</b>은 매번 최솟값을 찾아서 앞쪽에 배치하는 방식으로, 역시 <b>O(n²)</b>의 시간복잡도를 갖지만 교환 횟수가 적어 메모리 쓰기가 비싼 환경에서는 고려해볼 수 있는 정렬 방식입니다.
  
  <b>삽입 정렬</b>은 두 번째 요소부터 시작해서 그 앞에 존재하는 원소들과 비교하여 올바른 위치를 찾아 삽입하는 정렬 알고리즘입니다. 최악의 경우 <b>O(n²)</b>의 시간복잡도를 갖지만 거의 정렬된 데이터에 대해서는 <b>O(n)</b>에 가까워서 효율적입니다.
  
  <b>병합 정렬</b>은 주어진 배열을 크기가 1이 될 때까지 나누고 각각을 정렬한 후 합치는 <b>분할 정복 방식</b>에 기반한 정렬 알고리즘입니다. 항상 <b>O(n log n)</b>의 시간복잡도를 보장하고 안정 정렬이라는 장점이 있으나 추가 메모리가 필요하다는 단점이 있습니다.
  
  <b>퀵 정렬</b>은 피벗(Pivot)을 설정하고 피벗을 기준으로 작은 값은 왼쪽, 큰 값은 오른쪽으로 분할하는 <b>분할 정복 방식</b>에 기반한 정렬 알고리즘입니다. 병합 정렬과 달리 리스트를 비균등하게 분할하며, 평균적으로 <b>O(n log n)</b>의 시간복잡도를 가지고, 제자리 정렬이 가능해서 널리 사용됩니다. 다만 최악의 경우 시간복잡도는 <b>O(n²)</b>이 될 수 있습니다.
  
  <b>힙 정렬</b>은 힙 자료구조를 이용한 정렬로, 주어진 데이터를 힙 자료구조로 만들어 최댓값 또는 최솟값부터 하나씩 꺼내서 정렬하는 알고리즘입니다. 항상 <b>O(n log n)</b>을 보장하고 제자리 정렬이 가능합니다. 하지만 불안정 정렬이고 실제로는 퀵 정렬보다 느린 경우가 많습니다.
</details>
<details>
  <summary>DFS와 BFS에 대해 설명해주세요.</summary><br>

  DFS와 BFS는 그래프나 트리를 탐색하는 두 가지 기본적인 알고리즘입니다.

  <b>DFS(Depth First Search)</b>는 한 방향으로 계속 깊게 들어가다가 더 이상 갈 곳이 없으면 뒤로 돌아와서 다른 경로를 탐색하는 방식입니다.<br>
  구현은 보통 재귀나 스택을 사용하며, 현재 노드를 방문 처리하고, 인접한 노드들을 하나씩 재귀 호출하는 식으로 구현합니다.<br>
  DFS는 메모리를 적게 사용하지만 최단 경로를 보장하지 않습니다.<br>
  
  <b>BFS(Breadth Fisrt Search)</b>는 현재 레벨의 모든 노드를 먼저 방문하고, 그 다음 레벨로 넘어가는 방식입니다.<br>
  이는 큐를 사용해서 구현하는데, 시작 노드를 큐에 넣고, 큐에서 하나씩 빼면서 그 노드의 인접 노드들을 다시 큐에 넣는 과정을 반복하는 식으로 구현합니다.<br>
  BFS는 DFS에 비해 메모리를 더 많이 사용하지만 최단 경로를 찾을 수 있습니다.<br>
  
  시간 복잡도는 둘 다 O(V + E)로 동일합니다.
</details>
